# 音视频技术的简单科普

![说明图]()

## 一、为什么存在不同的传输协议和视频格式？

在各种技术科普之前，首先需要理解一个问题：

为什么会有这么多不同的流媒体传输协议（比如 `HLS`、`RTMP`、`WebRTC` 等）和视频格式（比如 `MP4`、`TS`、`FLV`、`MKV` 等）？

答案可以归结为以下几个原因:

### 1. 音视频数据的特性

**数据量巨大**
原始的音视频数据是非常庞大的。例如，一分钟未经压缩的 `1080p`、`30fps` 视频,其数据量可能达到数 GB。直接传输如此巨大的数据对网络带宽和存储都是巨大的挑战。因此，需要各种压缩算法（即编码方式）来减小数据体积。不同的编码方式（如 `H.264`, `H.265`, `VP9`, `AV1`）在压缩率、画质、计算复杂度等方面各有优劣，适用于不同的场景。

**实时性要求**
对于直播等场景来说，音视频数据的实时传输至关重要。一些协议（如 `RTMP`, `WebRTC`）被设计为低延迟，而另一些协议（如 `HLS`）则更侧重于传输的稳定性和兼容性，延迟相对较高。

**同步要求**
音频和视频是分开编码与传输的，在播放端需要确保它们的同步，否则会出现音画不同步的问题,哪怕只有 `30ms` 的音画不同步人类都可以感知得到。封装格式（`Container Format`）的一个重要作用就是将音视频流以及相关的元数据（如字幕、时间戳）打包在一起，并提供同步信息。

### 2. 网络环境的复杂性

**带宽波动**
互联网的带宽是不稳定的，用户的网络状况千差万别，且可能随时发生变化。为了保证流畅的观看体验，需要能够根据网络状况动态调整视频码率的技术，这就是自适应码率（`Adaptive Bitrate Streaming`, `ABR`）技术。`HLS` 和 `MPEG-DASH` 等协议都支持 `ABR`。

**网络协议差异**
底层的网络传输协议主要有 `TCP` 和 `UDP`。`TCP` 提供可靠的、面向连接的传输，能保证数据不丢失、不重复、按序到达，但其重传和拥塞控制机制可能引入较大延迟。`UDP` 则是不可靠的、无连接的传输，速度快、开销小，但可能丢包。不同的流媒体协议会根据其设计目标选择合适的底层传输协议，或者在应用层实现类似 `TCP` 的可靠性机制（如 `SRT`）。例如，`RTMP` 主要基于 `TCP`，而 `RTP` (`RTSP` 使用的基础协议之一) 通常基于 `UDP`。一些基于 `HTTP` 的协议（如 `HLS`, `DASH`, `HTTP-FLV`）则利用了 `HTTP` 协议的广泛兼容性和穿墙能力。

**防火墙和 NAT 穿透**
很多网络环境存在防火墙或网络地址转换（`NAT`），这可能阻碍某些协议的直接通信。基于 `HTTP` 的协议（如 `HLS`、`DASH`）通常更容易穿透防火墙，因为 `HTTP` 是标准的 Web 协议。

### 3. 应用场景的多样性

**直播 vs 点播**
直播对实时性要求更高，而点播则更注重播放的灵活性（如拖动进度条、选择清晰度）。不同的协议和格式针对这些场景有不同的优化。

**设备和平台兼容性**
不同的设备（PC、手机、智能电视、机顶盒）和操作系统（Windows, macOS, iOS, Android）对音视频格式和协议的支持程度不同。例如，`HLS` 最初由苹果公司推出，在 iOS 设备上有天然的良好支持。`MPEG-DASH` 是一个开放的国际标准，旨在提供更广泛的兼容性,但在中国市场却又缺乏厂商支持。

**版权保护 (DRM)**
对于商业内容，数字版权管理 (`DRM`) 是必不可少的。一些封装格式和传输协议（如 `MPEG-DASH` 结合 `CENC`）设计时就考虑了 `DRM` 的集成。

**交互性需求**
对于需要实时互动的场景（如视频会议、在线教育），`WebRTC` 这样的协议因其低延迟和 P2P 通信能力而更受青睐。

### 4. 历史和商业因素

**技术演进**
流媒体技术本身在不断发展，新的编码标准、封装格式和传输协议不断涌现，以满足更高的画质、更低的码率、更低的延迟等需求。旧的技术和格式可能因为历史原因仍然存在并被广泛使用。

**厂商推动**
一些公司为了推广自家的产品或生态系统，会推出特定的协议或格式。例如，Adobe 的 `Flash` 和 `RTMP`/`FLV` 曾经在 PC Web 端占据主导地位。苹果的 `HLS` 则是移动端流媒体的重要推手。

综上所述，没有一种"万能"的传输协议或视频格式能够完美适应所有场景。它们是在满足不同需求、克服不同挑战、平衡各种因素（如质量、延迟、成本、兼容性）的过程中逐步演化和分化出来的。因此，理解它们各自的特点和适用场景，对于进行流媒体相关的开发和决策至关重要。


## 二、编解码（Codec）

上一部分提到了音视频数据的"压缩"和"打包"，这正是由编解码器和封装格式来完成的。这两者是理解流媒体技术的基石。

### 1. 编解码（Codec）
`Codec` 是 "`Coder-DecCoder`"（编码器-解码器）的缩写。顾名思义，它包含两个过程：

- **编码（Encoding）**
  将原始的、未经压缩的音视频数据（通常非常巨大）转换为更小的、适合存储和传输的压缩格式的过程。编码过程会利用各种算法去除数据中的冗余信息。
- **解码（Decoding）**
  将压缩后的音视频数据还原为可供播放的原始或近似原始数据的过程。
    
### 2. 为什么需要编解码？

核心原因在于原始音视频数据体积过于庞大。例如，一段几分钟的高清视频，未经压缩可能占用数十 GB 的存储空间，这对于网络传输和设备存储都是不现实的。通过编解码技术，可以将数据体积压缩几十倍甚至上百倍，同时尽可能保持可接受的音视频质量。

**编解码的分类：**

- **有损压缩（Lossy Compression）**
  在压缩过程中会丢失一部分原始数据，这些数据通常是人类感知系统不太敏感的部分。有损压缩可以实现非常高的压缩率，但解压后的数据与原始数据不完全一致，质量会有一定程度的下降。绝大多数面向最终用户的音视频编解码器都采用有损压缩，如 `H.264`, `AAC`。
- **无损压缩（Lossless Compression）**
  在压缩过程中不丢失任何原始数据，解压后的数据与原始数据完全一致。无损压缩的压缩率相对较低，主要用于对质量要求极高的专业领域，如视频编辑、母带存档。例如 `FLAC` (音频), `FFV1` (视频)。

### 3. 常见的视频编解码器：

视频编码的核心思想是去除图像序列在时间维度和空间维度上的冗余。

- **空间冗余（Intra-frame Prediction / Spatial Compression）**
  指同一帧图像内像素之间的相关性。例如，一片蓝天中，相邻像素的颜色值非常接近。编码器可以只记录一个基准颜色和一些差异值，而不是每个像素的完整颜色信息。
- **时间冗余（Inter-frame Prediction / Temporal Compression）**
  指视频序列中相邻帧之间的相关性。例如，一个固定机位的场景中，背景在连续多帧内可能完全没有变化，或者只有微小的变化。编码器可以将第一帧（称为 `I 帧`或关键帧）完整编码，后续的帧（称为 `P 帧`或 `B 帧`）只记录与前一帧或后一帧的差异部分以及运动信息（运动矢量）。

- **`I 帧` (Intra-coded Picture)**
  ：帧内编码帧，也叫关键帧。它不依赖于其他帧，可以独立解码成一幅完整的图像。`I 帧`的压缩率相对较低，但它是随机访问（如拖动进度条）的基础。
- **`P 帧` (Predicted Picture)**
  ：前向预测编码帧。它需要参考前面的 `I 帧`或 `P 帧`才能解码。`P 帧`记录的是与参考帧的差异，压缩率较高。
- **`B 帧` (Bidirectionally Predicted Picture)**
  ：双向预测编码帧。它既需要参考前面的 `I 帧`或 `P 帧`，也需要参考后面的 `P 帧`或 `I 帧`才能解码。`B 帧`的压缩率最高，但解码延迟也相对较大。

一个典型的视频帧序列可能是 `IBBPBBPBBP...` 这样的结构，称为一个 `GOP` (Group of Pictures)。

![说明图]()

以下是一些主流的视频编解码器：

#### H.264 / AVC (Advanced Video Coding)
目前应用最广泛的视频编码标准，由 ITU-T 的 VCEG 和 ISO/IEC 的 MPEG 共同开发。它在压缩效率、画质和计算复杂度之间取得了较好的平衡，被广泛应用于网络流媒体、蓝光光盘、数字电视广播等领域。具有多种档次 (`Profile`) 和级别 (`Level`)，以适应不同应用场景的需求。

> 注: `Profile`和`Level`是编码层面信息,和协议无直接关系

| Profile 类型 | 技术特性 | 适用场景 |
| :--- | :--- | :--- |
| **Baseline** | 仅支持I/P帧、CAVLC熵编码，无B帧和CABAC | 移动端视频通话、低功耗设备(最广泛) |
| **Main** | 支持I/P/B帧、CABAC熵编码，引入去块滤波 | 标清电视、蓝光视频 |
| **High** | 扩展支持8x8像素块预测、无损编码、YUV 4:4:4色度采样 | 专业广播、高画质流媒体 |

| 协议 | Profile/Level 存储位置 | 是否显式包含 | 典型应用场景 |
| :--- | :--- | :--- | :--- |
| **HLS** | 编码器配置隐含，TS 文件不携带 | ❌ | 高兼容性点播/直播 |
| **FLV** | 文件头元数据明确标注 | ✔️ | 低延迟直播 |
| **RTMP** | 握手元数据与视频包头 | ✔️ | 推流 |

#### H.265 / HEVC (High Efficiency Video Coding)
`H.264` 的后继者，同样由 `VCEG` 和 `MPEG` 联合制定。相比 `H.264`，`HEVC` 能在保持同等画质的情况下将码率降低约 50%，或者在同等码率下提供更高的画质。主要用于 4K/8K 超高清视频、HDR 视频等。

**专利与推广的困境**
`HEVC` 的普及速度远不如其前辈 `H.264`，主要归咎于其极其复杂的专利授权结构和高昂的。其专利权分散在多个专利池（如 `MPEG LA`, `HEVC Advance`, `Velos Media`）以及一些未加入专利池的独立公司手中。部分专利持有者，特别是 `HEVC Advance`，早期提出了非常激进且不透明的专利政策，例如不仅对硬件设备收费，还试图对内容分发（如按流媒体服务订阅用户数或内容时长）收费，甚至提出过按终端用户设备数量收取专利费用的想法，这引起了业界的广泛抵制和担忧。这种"专利丛林"和部分权利人的"贪婪"策略，使得许多设备制造商、内容提供商和软件开发者对采用 `HEVC` 持谨慎态度，担心陷入不可预测的法律风险和高昂的成本。这成为了一个典型的资本逐利影响技术发展的案例，并直接催生了业界巨头联合组建 `AOMedia`，力推免授权费的 `AV1` 作为替代方案。

**浏览器与操作系统支持**
主流浏览器（如 `Chrome`）早期并未内置 `HEVC` 解码支持，除了开放标准的考量外，复杂的专利问题也是一个重要原因。目前，浏览器对 `HEVC` 的支持主要依赖于操作系统层面提供的硬件解码能力。Intel (`Quick Sync Video`), AMD (`VCE/VCN`), Nvidia (`NVDEC`) 等主流 CPU/GPU 厂商在其芯片中集成了 `HEVC` 硬解模块，它们通常已经支付了相关的专利费用。当操作系统（如 Windows 10+, macOS High Sierra+, Android 5.0+, iOS 11+）集成了对这些硬件解码能力的支持后，浏览器可以通过调用系统提供的媒体框架 API (如 `Windows Media Foundation`, `VideoToolbox` on Apple platforms, `MediaCodec` on Android) 来实现 `HEVC` のハードウェアデコード再生，これにより、ブラウザ自体が `HEVC` デコードソフトウェアを含むことによる特許ライセンス問題に直接直面するのを避けることができます。もしブラウザやウェブアプリケーションが JavaScript（例えば `WebAssembly` でコンパイルされた `libde265.js`）を介して `HEVC` のソフトウェアデコードを選択した場合、理論的には特許問題に触れる可能性が依然としてあり、CPU消費が大きく、ユーザーエクスペリエンスが悪いため、通常は互換性のためのバックアップ手段としてのみ使用されます。

#### VP9
由 `Google` 开发并主导的开放、免专利费的视频编码格式，作为 `VP8` 的继任者。主要应用于 `YouTube` 等 Google 的服务。其压缩性能与 `HEVC` 相当。

#### AV1 (AOMedia Video 1)
由开放媒体联盟 (`Alliance for Open Media`, `AOMedia`) 开发的开放、免专利费的视频编码格式，旨在取代 `VP9` 并与 `HEVC` 竞争。其成员包括 `Google`, `Mozilla`, `Microsoft`, `Apple`, `Amazon`, `Netflix`, `Intel`, `NVIDIA` 等行业巨头。`AV1` 的目标是提供比 `HEVC` 和 `VP9` 更高的压缩效率（通常能再降低 20-30% 的码率），但其编码复杂度和解码复杂度也更高，对硬件性能要求较高。

**硬件解码支持**
`AV1` 的硬件解码支持正在快速发展。截至 2024 年，许多新的高端设备和芯片已开始集成 `AV1` 硬解能力。例如，苹果从 `A17 Pro` (iPhone 15 Pro) 和 `M3/M4` 系列芯片开始支持；主流 Android 旗舰芯片（如高通骁龙 8 Gen 2 及更新版本、联发科部分天玑高端芯片）、新的智能电视、流媒体设备（如较新的 Chromecast with Google TV, Amazon Fire TV Stick 4K Max）以及桌面级显卡（NVIDIA GeForce RTX 30/40 系列, AMD Radeon RX 6000/7000 系列, Intel Arc 系列）都已提供 `AV1` 硬件解码。尽管如此，考虑到庞大的存量设备，`AV1` 硬解在整个市场的"完全普及"尚需时日，但其增长势头迅猛，生态系统正在快速成熟。

**软件解码**
对于不支持硬件解码的设备，高效的开源软件解码器（如 `dav1d`）也使得在性能尚可的设备上播放中低分辨率的 `AV1` 视频成为可能，但对于高分辨率或高帧率内容，软解的功耗和 CPU 占用仍然是挑战。

**应用**
`YouTube`、`Netflix` 等大型视频平台已经开始在其内容库中使用 `AV1`，尤其是在对带宽敏感或对画质有更高要求的场景。主流浏览器（`Chrome`, `Firefox`, `Edge`, `Safari 17+`）也已支持 `AV1` 播放。

#### MPEG-2
较早的视频编码标准，主要用于 DVD、数字电视广播（如 `DVB`, `ATSC`）。压缩效率不如 `H.264`。

### 4. 常见的音频编解码器：

音频编码主要利用人类听觉系统的掩蔽效应等心理声学原理来去除冗余信息。

- **`AAC` (Advanced Audio Coding)**
  由 `MPEG` 开发，作为 `MP3` 的后继者。在相同的码率下，`AAC` 通常能提供比 `MP3` 更好的音质。广泛应用于数字广播、网络流媒体、苹果设备等。有多种规格，如 `AAC-LC` (Low Complexity), `HE-AAC` (High-Efficiency AAC) 等。
- **`MP3` (MPEG-1 Audio Layer III)**
  曾经最流行的有损音频压缩格式，普及率极高。
- **`Opus`**
  一个完全开放、免专利费、高度通用的有损音频编解码器，由 Xiph.Org 基金会开发，并由 IETF 标准化。它设计用于从低比特率的窄带语音到高比特率的立体声音乐等各种应用场景，特别擅长处理交互式实时音频（如 `VoIP`, `WebRTC`），具有低延迟特性。
- **`FLAC` (Free Lossless Audio Codec)**
  一种著名的无损音频压缩编码，可以将原始音频数据压缩约 40%-60% 而不损失任何信息。常用于音乐发烧友存储和播放高质量音乐。
- **`PCM` (Pulse Code Modulation)**
  脉冲编码调制，是一种未经压缩的原始数字音频格式，通常作为其他音频编码的输入或输出。例如，CD 音轨就是 `PCM` 编码。

选择哪种编解码器，通常需要权衡压缩效率、音视频质量、编解码计算复杂度（对设备性能的要求）、兼容性以及专利授权成本等因素。

### 5. 软解码 (Software Decoding) vs. 硬解码 (Hardware Decoding)

在讨论编解码器时，一个重要的相关概念是解码方式：软解和硬解。这直接影响到播放性能和用户体验。

#### 硬解码 (Hardware Decoding)
- **定义**
  ：指利用设备上专门的硬件电路（通常集成在 GPU、SoC - System on Chip，或专用的视频处理单元 VPU - Video Processing Unit 中）来执行视频解码运算的过程。
- **优点**
  - **高效率、低功耗**：专用硬件执行特定任务远比通用 CPU 高效，因此解码速度快，CPU 占用率极低，设备发热小，能显著延长移动设备的电池续航。
  - **流畅播放高清内容**：对于 `1080p`, `4K` 甚至 `8K` 等高分辨率、高码率视频，硬解是保证流畅播放的关键。
- **缺点**
  - **依赖硬件支持**：只有当设备的硬件明确支持某种编码格式时，才能进行硬解。例如，较老的设备可能不支持 `HEVC` 或 `AV1` 的硬解。
  - **驱动和兼容性问题**：硬件驱动程序的问题也可能导致硬解失败或出现兼容性问题。

- **例子**
  现代手机的芯片、PC 的显卡、智能电视和机顶盒的 `SoC` 通常都内置了对 `H.264`, `H.265` 等主流编码的硬件解码模块。浏览器、操作系统媒体框架（如 Windows 的 `Media Foundation`, Android 的 `MediaCodec`, macOS/iOS 的 `VideoToolbox`）以及第三方播放器（如 `PotPlayer`, `IINA`）在播放视频时会优先尝试启用硬解。

#### 软解码 (Software Decoding)
- **定义**
  指完全依靠通 CPU 来执行视频解码算法的过程。
- **优点**
  - **高兼容性**：不依赖特定的硬件解码模块，只要有相应的解码库（软件）和足够的 CPU 处理能力，理论上可以播放任何编码格式的视频。
  - **快速支持新格式**：对于新兴或不常见的编码格式，软解往往能更快地提供支持。
- **缺点**
  - **CPU 负载高**：解码计算密集型任务，对 CPU 性能要求高，尤其是在处理高清、高码率视频时，容易导致 CPU 占用率飙升。
  - **高功耗、易发热**：高 CPU 负载意味着更大的电力消耗和更多的热量产生，对笔记本和移动设备续航不利，也可能导致设备过热降频，影响整体性能。
  - **可能无法流畅播放**：如果 CPU 性能不足以实时解码视频流，就会出现播放卡顿、掉帧等现象。
- **例子**
  `VLC Media Player` 以其强大的软解能力著称，能够播放许多特殊或损坏的视频文件。
  `FFmpeg` 库本身主要提供软编解码能力，被许多播放器和转码工具用作核心引擎。
  如前所述，在浏览器中通过 `WebAssembly` 运行 `HEVC` 或其他格式的解码库（例如 `libde265.js` for `HEVC`, `dav1d.js` for `AV1`），就是一种典型的软解应用场景，用于在浏览器原生不支持硬解或硬解失败时作为后备方案。
  国内一些视频网站曾经为了节省流量成本,做出过在用户浏览器开大量`WebWorker`进行解码的操作。导致开启页面笔记本风扇就会高速运转。

在实际应用中，播放器通常会优先尝试硬解码。如果硬解码不可用（设备不支持、驱动问题、编码参数不支持等）或被禁用，则会回退到软解码。理想情况下，用户应该尽可能使用硬解码以获得最佳的播放体验和能效比。


## 三. 封装格式（Container Format）

如果说编解码器是负责处理"食材"（原始音视频数据）并将其"烹饪"（压缩）成可口的"菜肴"（压缩后的音视频流），那么封装格式（也称容器格式）就好比是"餐盒"或"盘子"，它负责将这些"菜肴"以及其他"辅料"（如字幕、章节信息、元数据）打包在一起，方便"运送"（存储和传输）和"享用"（播放）。

**封装格式的核心作用：**

- **流的复用 (Multiplexing)**
  将编码后的视频流、一个或多个音频流、字幕流等不同的数据流合并到一个单独的文件或数据流中。
- **同步 (Synchronization)**
  提供音视频同步机制，确保播放时音频和视频能够准确对应，避免出现音画不同步的现象。这通常通过在数据流中嵌入时间戳 (`Timestamp`) 来实现。
- **元数据 (Metadata) 存储**
  存储关于音视频内容的描述信息，如标题、作者、专辑、封面、编码参数、帧率、分辨率、时长、章节信息等。
- **索引 (Indexing)**
  提供索引信息，使得播放器可以快速定位到文件的特定位置，支持随机访问（如拖动进度条播放）。

**重要的概念：**

- **流 (Stream)**
  指连续的音视频数据序列，例如 `H.264` 视频流、`AAC` 音频流。
- **轨道 (Track)**
  封装格式中的一个逻辑通道，用于承载特定类型的流。一个文件可以包含多个视频轨道（例如不同角度）、多个音频轨道（例如不同语言）、多个字幕轨道等。

**常见的封装格式：**

封装格式通常由文件扩展名来标识，但需要注意的是，文件扩展名并不直接代表音视频的编码格式。同一个封装格式可以容纳不同编码的音视频流，反之，同一种编码的音视频流也可以被封装在不同的格式中。

#### MP4 (.mp4)
基于 ISO 基本媒体文件格式 (`ISO Base Media File Format`, `ISOBMFF`)，是目前最流行和通用的封装格式之一。它可以包含 `H.264`, `H.265`, `MPEG-4 Visual`, `AAC`, `MP3` 等多种编码的音视频流。广泛用于网络视频、移动设备、数码相机等。`MP4` 文件结构复杂，包含一系列被称为`atom`(有时也叫`box`)的数据单元，用于存储元数据和媒体数据。

以下是一个mp4文件的内部结构
![说明图]()

每个节点都可以算作一个`atom` 其中最为关键的是 `moov`

- **`moov`**
  `moov` 包含了文件的所有元数据，如索引信息、时长、每个媒体数据块 (`mdat` atom) 的位置等。为了实现在网络传输中常见的"边下载边播放"（即渐进式下载或伪流式传输），`moov` atom 必须位于文件的开头。这样，播放器在下载文件初始数据后，就能立即解析 `moov` atom 获取播放所需的全部元信息，从而开始播放，并在后台继续下载实际的音视频数据（存储在 `mdat` atom 中）。许多视频编码工具提供了"`Fast Start`"或类似选项，以确保在生成 MP4 文件时将 `moov` atom 放置在文件头部。

#### MOV (.mov)
由苹果公司开发，与 `MP4` 格式非常相似，事实上 `MP4` 格式就是基于 QuickTime 文件格式 (`MOV`) 发展而来的。常用于苹果生态系统，如 `QuickTime` 播放器、`Final Cut Pro` 编辑软件等。

#### MKV (Matroska Video, .mkv, .mka, .mks)
一个开放标准的、功能强大的封装格式，以其灵活性和先进特性著称。它可以容纳几乎所有类型的视频、音频、字幕编码，支持多轨道、章节、菜单等。常用于存储高清和超高清电影，尤其是在非商业发行领域。

#### FLV (Flash Video, .flv)
由 Adobe 公司为其 Flash 平台开发的封装格式。主要用于在网络上传输流媒体内容。`FLV` 文件结构相对简单，通常包含一个文件头和一系列的 `Tag` (标签)，每个 `Tag` 可以是视频数据、音频数据或脚本数据 (元数据)。`FLV` 支持的视频编码主要是 `Sorenson Spark` (`H.263`) 和 `VP6`，后来也支持了 `H.264` (需要 `AVC Tag`)。音频编码主要是 `MP3` 和 `AAC`。随着 `Flash` 的没落，`FLV` 的使用逐渐减少，但基于 HTTP 的 `FLV` 直播 (`HTTP-FLV`) 仍然是一些直播平台采用的技术。

#### TS (MPEG Transport Stream, .ts, .m2ts)
`MPEG-2` 传输流，主要为数字电视广播（如 `DVB`, `ATSC`）和蓝光光盘设计。其特点是将数据分割成固定大小 (通常是 188 字节) 的包 (`Packet`) 进行传输，具有较强的容错能力，适合在不太可靠的信道上传输。`TS` 流可以包含 `MPEG-2 Video`, `H.264`, `H.265` 等视频编码和 `MPEG-1 Audio Layer II`, `AAC`, `AC-3` 等音频编码。`HLS` 协议就是基于 `TS` 文件片段的。

#### AVI (Audio Video Interleave, .avi)
由微软公司于 1992 年推出，是 Windows 平台上非常早期的封装格式。结构相对简单，但缺乏对现代编码和流媒体特性的良好支持（如 `B 帧`处理、时间码标准不一等）。虽然老旧，但因其历史悠久，仍有一定的存量。

#### WebM (.webm)
一种开放、免专利费的媒体文件格式，专门为 `HTML5` 视频设计。它通常使用 `VP8` 或 `VP9` 视频编码，以及 `Vorbis` 或 `Opus` 音频编码。由 Google 等公司推动。

#### ASF (Advanced Systems Format, .asf, .wmv, .wma)
微软开发的封装格式，用于 Windows Media。`WMV` (Windows Media Video) 和 `WMA` (Windows Media Audio) 是基于 `ASF` 的具体应用。

选择哪种封装格式，需要考虑其支持的编解码器、特性（如字幕、多轨道支持）、流媒体友好性、兼容性以及特定应用场景的需求。

总而言之，编解码器负责内容的"质"，即音视频数据如何被压缩和表示；而封装格式负责内容的"形"，即将这些压缩后的数据以及相关信息如何组织和打包。两者协同工作，才构成了我们日常接触到的各种音视频文件和流媒体服务。


## 四、不同协议、格式的适用场景及原理

在了解了各种编解码技术、传输协议以及封装格式后，我们现在可以更深入地探讨它们在不同应用场景下的适用性以及背后的原理。选择正确的技术组合对于优化用户体验、控制成本以及满足特定业务需求至关重要。

### 1. 直播（Live Streaming）

直播场景的核心诉求通常包括：低延迟、高并发、高可用性、良好的兼容性。

#### 1.1 推流端

推流是指将实时音视频流发送到流媒体服务器的过程。

##### RTMP (Real-Time Messaging Protocol)

- **适用场景**
  目前仍然是**最主流的直播推流协议**，尤其是在 PC 端使用 `OBS`等软件推流到各大直播平台或自建流媒体服务器时。
- **原理与优势**
  - **低延迟**：基于 `TCP`，通过精心设计的消息机制和较小的缓冲区，`RTMP` 能够实现 1-3 秒的较低推流延迟。
  - **广泛的软硬件支持**：大量的编码器硬件、推流软件以及流媒体服务器（如 `Nginx-RTMP`, `SRS`）都原生支持 `RTMP` 推流。
  - **稳定性**：`TCP` 保证了数据传输的可靠性，对于推流这种上行带宽相对可控的场景，其稳定性表现良好。
- **局限性**
  - **播放端兼容性差**：由于 `Flash` 的淘汰，`RTMP` 不再适合直接用于 Web 端播放。
  - **端口限制**：如前所述，其 `1935` 端口可能被防火墙阻挡，需要 `RTMPT`/`RTMPS` 等变种协议。
  - **不支持 HEVC (H.265)**：标准 `RTMP` 协议主要支持 `H.264` 和 `AAC`。虽然有非标准扩展支持 `HEVC`，但通用性不强。

##### SRT (Secure Reliable Transport)

- **适用场景**
  主要使用在电视台等广电行业。硬件导播台,编码器等专业设备原生集成了`SRT`.主要用于端到端传输. 和`WebRTC` 相比更符合广电行业强监管的特性。
- **原理与优势**
  - **低延迟与高可靠性**：`SRT` 虽然基于 `UDP`，但在应用层实现了丢包重传机制和前向纠错能力，能在保证低延迟的同时，有效对抗网络抖动和丢包。
  - **安全性**：支持 `AES-128/256` 加密。
  - **NAT穿透能力**：因为其基于 `UDP` ,所以在网络穿透方面更有优势。
  - **多链路聚合**：多链路聚合一句话概括是把**多条物理链路整合为单一逻辑通道**比如大型赛事现场,拍摄人员使用插入4~8张sim卡的专业设备发起推流. 
- **局限性**
  使用场景相对较窄,基本上只能由专业设备发起。

##### WebRTC (Web Real-Time Communication)

- **适用场景**
  主要用于**浏览器内直接推流**，或者需要极低延迟的互动直播场景(例如直播带货和视频会议)
- **原理与优势**
  - **极低延迟**：为实时通信设计，延迟可控制在 1 秒以内。
  - **浏览器原生支持**：无需额外插件，用户在浏览器即可完成推流。
  - **安全性**：强制加密 (`DTLS-SRTP`)。
- **局限性**
  - **WebRTC 的服务器端部署和大规模分发相对复杂**，且其设计初衷更侧重于 P2P 或小规模互动，直接作为大规模单向直播的推流协议不如 RTMP/SRT 成熟。
  - **大规模单向分发复杂**：其 `SFU` (Selective Forwarding Unit) 或 `MCU` (Multipoint Control Unit) 服务器架构在应对超大规模并发观众时，比传统 CDN 分发 HLS/DASH 更具挑战性，成本也可能更高。
  - **对网络质量敏感**：虽然有拥塞控制和自适应机制，但 `UDP` 传输在极端恶劣网络下表现可能不如 `TCP` 稳定（除非上层应用做了很好的保障）。

**公有云的大规模 WebRTC 直播应用**

尽管存在上述挑战，但凭借其亚秒级的延迟特性，`WebRTC` 技术栈已被一些领先的公有云厂商用于构建大规模、超低延迟的直播服务（有时被称为"快直播"、"零延迟直播"），特别适用于像直播带货这样对实时互动要求极高的场景。这通常需要云厂商具备强大的全球分布式媒体处理节点、智能路由技术以及深厚的音视频研发和运维能力。由于难以充分利用传统基于文件分发的 `CDN` 缓存优势，这类大规模 `WebRTC` 直播服务的单位带宽成本通常也高于传统的 `HLS`/`DASH` 直播。

#### 1.2 拉流端

拉流是指观众从流媒体服务器或 `CDN` 获取音视频流进行播放的过程。

**直播中的转码与转协议**

在实际的直播业务中，从推流端到拉流端，往往不仅仅是单一协议的传输，中间通常会涉及到"转码"和"转协议"的过程，这两个环节对于保障直播质量和兼容性至关重要。

- **转码 (Transcoding)**
  - **原因**：原始推流的码率、分辨率、编码格式可能并不适合所有观众的设备和网络条件。例如，主播可能推了 `1080p` 的 `H.264` 高码率流，但部分观众网络较差或设备性能不足。
  - **目的**：在流媒体服务器端，将接收到的原始流实时转换为多种不同清晰度（如 `1080p`, `720p`, `480p`）、不同码率的视频流，通常保持音频编码和参数一致或也进行相应处理。这是实现自适应比特率 (`ABR`) 播放的基础。有时也会涉及编码格式的转换（如 `H.264` 转 `H.265` 以节省带宽，但这会增加服务器计算压力）。
  - **位置**：通常在流媒体服务器接收到推流之后，进行分发（如切片、生成播放列表）之前。

- **转协议 (Transmuxing/Protocol Conversion)**
  - **原因**：推流协议（如 `RTMP`, `SRT`）往往不适合直接用于大规模终端用户播放，或者不同播放端对协议的兼容性要求不同。
  - **目的**：将一种协议封装的音视频数据，转换为另一种协议封装。例如，服务器接收 `RTMP` 推流后，可以将其转换为 `HLS`、`MPEG-DASH`、`HTTP-FLV` 等协议，再通过 `CDN` 分发给观众。这个过程通常只改变封装方式，不改变音视频的编码（除非同时进行转码）。
  - **位置**：流媒体服务器在接收推流后，根据需要分发给不同协议的客户端时进行。

**客户端预处理/多路推流**

为了降低云端服务器的实时转码压力和成本，一些直播平台可能会要求或推荐主播使用其定制的推流软件。

这类软件可能在主播端（用户电脑上）就利用本地计算资源，对原始采集的音视频进行预处理，甚至直接生成并推送多路不同码率/分辨率的视频流到服务器。

例如，主播的电脑性能较好时，推流软件可能同时编码输出 `1080p` 的主流和 `720p` 的次流。这样，服务器接收到的已经是适配好的多路流，只需进行简单的转协议和分发即可。这种方式虽然有效降低了云端成本，但也意味着将一部分计算压力转移到了主播端，可能导致主播电脑的 `CPU`/`GPU` 占用较高，对硬件性能提出更高要求。这也是为什么有些平台强制或优先推荐使用其官方推流软件，而不是通用的第三方软件（如 `OBS`）的原因之一，以便更好地控制推流参数和实现此类优化策略。

##### HTTP-FLV (FLV over HTTP)

- **适用场景**
  对延迟有较高要求的 **PC Web 端直播播放**，尤其是在国内广泛应用。
- **原理与优势**
  - **低延迟**：通过 HTTP 长连接模拟流式传输 `FLV` 数据，延迟可以做到与 `RTMP` 相当 (1-3 秒)。
  - **HTTP 友好**：基于 `HTTP`，易于穿透防火墙，可复用 `HTTP` 服务器和 `CDN` 基础设施。
  - **实现简单**：相比 `HLS`/`DASH`，服务器端改造相对简单。

##### HLS (HTTP Live Streaming)

- **适用场景**：
  **兼容性要求高、需要大规模 `CDN` 分发、对延迟容忍度稍高（如 5-30 秒）的直播场景**。是目前 Web 和移动端直播播放最主流的选择之一。
- **原理与优势**：
  - **极佳的兼容性**：iOS/macOS 原生支持，Android 和主流浏览器通过 JavaScript 播放器（如 [`hls.js`](https://github.com/video-dev/hls.js)）也能良好支持。
  - **`CDN` 友好**：基于 `HTTP` 短连接和标准文件格式 (`TS`, `M3U8`)，与 `CDN` 架构完美契合，分发效率高，成本相对较低。
  - **自适应比特率 (`ABR`)**：天然支持 `ABR`，客户端可根据网络状况平滑切换码率，提升观看体验。
- **局限性**：
  - **原生延迟较高**：传统的 `HLS` 基于文件切片和播放列表更新机制，导致延迟较大。
  - **切片开销**：频繁的切片生成和请求可能带来一定的服务器和网络开销。

**低延迟 HLS (LL-HLS)**：通过缩短切片时长、分块传输编码 (`Chunked Transfer Encoding`)、播放列表增量更新、`HTTP/2 PUSH` 等技术，`LL-HLS` 可以将延迟降低到 2-5 秒，甚至更低，使其在对延迟有一定要求的场景下更具竞争力。

##### MPEG-DASH (Dynamic Adaptive Streaming over HTTP)

- **适用场景**：
  与 `HLS` 类似，适用于**需要大规模 `CDN` 分发和 `ABR` 的直播场景**，尤其是在非苹果生态或需要更灵活编解码器选择的场合。
- **原理与优势**：
  - **国际标准，开放灵活**：编解码器中立，支持更广泛的音视频编码和 `DRM` 方案。
  - **`CDN` 友好与 `ABR`**：与 `HLS` 类似，基于 `HTTP`，易于 `CDN` 分发，支持 `ABR`。
  - **低延迟 DASH**：通过 `CMAF` (Common Media Application Format) 和分块传输等技术，`DASH` 也能实现较低的直播延迟。`CMAF` 旨在统一 `HLS` 和 `DASH` 的媒体片段格式，进一步提高分发效率。
- **局限性**：
  - **iOS 原生支持有限**：虽然可以通过 JavaScript 播放器（如 [`dash.js`](https://github.com/Dash-Industry-Forum/dash.js)）在 Safari 中播放，但原生支持不如 `HLS`。
  - **生态相对 HLS 稍弱**：在某些特定领域或设备上的支持和工具链可能不如 `HLS` 成熟。

##### WebRTC

- **适用场景**
  **需要极低延迟的互动直播场景**，如视频会议、在线教育、直播连麦、云游戏、远程控制等。
- **原理与优势**
  - **亚秒级延迟**：专为实时双向通信设计。
  - **浏览器原生，无需插件**
  - **P2P 能力**：在合适网络条件下可实现端到端通信，减轻服务器压力。
- **局限性**
  - **大规模单向分发复杂**：其 `SFU` (Selective Forwarding Unit) 或 `MCU` (Multipoint Control Unit) 服务器架构在应对超大规模并发观众时，比传统 `CDN` 分发 `HLS`/`DASH` 更具挑战性，成本也可能更高。
  - **对网络质量敏感**：虽然有拥塞控制和自适应机制，但 `UDP` 传输在极端恶劣网络下表现可能不如 `TCP` 稳定（除非上层应用做了很好的保障）。

#### 1.3 直播中的 CDN 分发原理

对于 `HLS`、`MPEG-DASH`、`HTTP-FLV` 这类基于 `HTTP` 的直播协议，内容分发网络 (`CDN`) 起着至关重要的作用。其基本原理如下：

1.  **源站与推流**：主播将音视频流通过 `RTMP`、`SRT` 等协议推送到源站流媒体服务器。
2.  **切片与索引生成**：源站服务器对接收到的流进行实时转码（如果需要多码率）、切片（如 HLS 的 `TS` 片段、DASH 的媒体片段）并生成相应的索引文件（如 `.m3u8`、`.mpd`）。
3.  **CDN 边缘节点缓存**：
    - 当第一个用户请求某个直播流时，其请求会被 `DNS` 智能解析或 `Anycast` 路由到离他最近的 `CDN` 边缘节点。
    - 如果该边缘节点没有缓存对应的索引文件和媒体片段，它会回源到上一级 `CDN` 节点或直接回源站去拉取。
    - 获取到数据后，边缘节点会将这些文件缓存起来，并响应给用户。
4.  **后续用户访问**：当其他用户（尤其是地理位置相近的用户）请求同一个直播流时，可以直接从已经缓存了内容的 `CDN` 边缘节点获取，无需回源，从而：
    - **降低源站压力**：绝大部分用户请求由 `CDN` 处理。
    - **提升用户体验**：用户从更近的节点获取数据，加载速度更快，播放更流畅。
    - **提高并发能力**：`CDN` 的分布式架构可以轻松应对百万甚至千万级别的并发观看。
5.  **索引文件更新**：对于直播，索引文件会不断更新，指向新的媒体片段。`CDN` 节点会根据配置的缓存策略（如 `TTL` - Time To Live）定期回源获取最新的索引文件，以保证用户能看到最新的直播内容。`LL-HLS`/`DASH` 的低延迟机制对 `CDN` 的缓存和刷新策略有更高要求。

选择 `CDN` 服务商时，需要考虑其节点分布、带宽储备、对低延迟协议的支持程度、回源策略、安全性以及成本等因素。

### 2. 点播（Video on Demand, VoD）

点播场景的核心诉求通常包括：播放流畅性、任意拖拽、清晰度选择、广泛的设备兼容性以及较低的存储和分发成本。

#### MP4 (Progressive Download)

- **适用场景**：
  **短视频、对 `CDN` 依赖不高、无需复杂 `ABR` 或 `DRM` 的简单点播场景**。
- **原理与优势**：
  - **实现简单**：直接将 `MP4` 文件放在 `HTTP` 服务器上即可。如果 `moov` atom 在文件头部，可以实现边下载边播放。
  - **兼容性好**：几乎所有设备和浏览器都原生支持 `MP4` 播放。
  - 单个文件易于管理。
- **局限性**：
  - **不支持 `ABR`**：无法根据用户网络状况动态调整码率。
  - **`CDN` 缓存不友好（对于大文件）**：如果用户只观看视频的一部分，`CDN` 可能仍需缓存整个大文件，效率不高。对于拖拽操作，如果 `moov` atom 很大或服务器不支持字节范围请求 (`byte-range requests`)，体验可能不佳。
  - **启动速度可能较慢（对于大文件）**：需要下载一部分数据（至少是 `moov` atom 和初始数据块）后才能开始播放。

#### HLS / MPEG-DASH

- **适用场景**：
  **长视频、需要 `ABR`、需要 `CDN` 高效分发、需要 `DRM` 版权保护的主流点播场景**。如在线视频平台（电影、剧集）、在线教育课程等。
- **原理与优势**：
  - **`ABR` 支持**：核心优势，提供最佳观看体验。服务器会预先将源视频转码并切分成多种码率的片段。客户端播放器根据 `MPD`/`M3U8` 文件中的信息和当前网络带宽，选择合适的片段进行下载和播放。
  - **`CDN` 高效分发**：与直播类似，基于 `HTTP` 的小片段非常适合 `CDN` 缓存和分发，用户可以从最近的节点获取数据，提高加载速度和播放流畅性。只下载观看的部分，节省带宽。
  - **快速启动和拖拽**：由于是分片加载，可以更快地开始播放，并且基于索引文件，可以较快地定位到指定时间点进行播放。
  - **`DRM` 支持**：`MPEG-DASH` (结合 `CENC`) 和 `HLS` (结合 `FairPlay Streaming` 等) 都有成熟的 `DRM` 解决方案。
  - **丰富特性**：支持多音轨、多字幕、章节等。
- **局限性**：
  - **实现复杂度略高**：需要对视频进行预处理（转码、切片）。
  - **存储开销略大**：因为需要存储多种码率的切片文件。

### 3. 互动场景 (Interactive Streaming)

如视频会议、在线教育小班课、直播连麦 PK 等。

#### WebRTC

- **适用场景**：
  **这类场景的首选，核心诉求是极低的双向或多向延迟**。
- **原理与优势**：
  见上文直播部分的 `WebRTC` 描述。其 `P2P` 连接能力在小规模互动中能有效降低服务器成本和延迟。对于多人场景，通常需要 `SFU` (Selective Forwarding Unit) 或 `MCU` (Multipoint Control Unit) 媒体服务器进行流的转发或混流。
- **局限性**：
  大规模分发（如将会议内容广播给成千上万的观众）仍需结合其他技术，例如将 `WebRTC` 流从媒体服务器输出，再转为 `HLS`/`DASH` 等协议通过 `CDN` 分发。

### 4. 特殊场景

#### 安防监控 (Surveillance)

##### RTSP/RTP/RTCP
- **适用场景**
  `IP` 摄像头、网络录像机 (`NVR`) 等传统安防设备的主要传输和控制协议。
- **原理与优势**
  `RTSP` 提供控制信令（如播放、暂停、录制），`RTP` 传输实时音视频数据（通常基于 `UDP` 以保证低延迟），`RTCP` 提供传输质量反馈。在局域网内，其低延迟和控制能力表现良好。
- **局限性**
  直接在公网或浏览器播放兼容性差，通常需要服务器将其转换为 `HLS`, `HTTP-FLV`, `WebRTC` 等格式。

##### GB/T 28181
国内安防领域的标准协议，基于 `SIP` (Session Initiation Protocol) 进行控制，媒体传输也常使用 `RTP`。

### 总结：如何选择？

选择合适的协议和格式是一个权衡的过程，需要综合考虑以下因素：

- **核心业务需求**：是直播、点播还是互动？对延迟的要求有多高？并发规模有多大？
- **用户端兼容性**：目标用户主要使用什么设备和平台？（iOS, Android, PC Web, 智能电视等）
- **内容特性**：是短视频还是长视频？是否需要高清/超高清？是否需要 `DRM`？
- **网络条件**：推流端和播放端的网络环境如何？是否需要考虑弱网优化？
- **成本预算**：包括开发成本、服务器成本、`CDN` 带宽成本、存储成本以及可能的专利授权费用。
- **技术栈和团队能力**：团队对哪些技术更熟悉？是否有能力驾驭复杂的技术方案？

通常，一个完善的流媒体系统可能会组合使用多种技术：

- **推流**：`RTMP` (通用) 或 `SRT` (高质量/不稳定网络) 或 `WebRTC` (浏览器/极低延迟互动)。
- **服务器处理**：接收推流，进行转码（如 `H.264`, `H.265`, `AAC`）、切片（生成 `HLS`/`DASH`）、录制、鉴权等。
- **分发**：
  - **直播**：`HTTP-FLV` (PC Web 低延迟)、`HLS`/`LL-HLS` (通用高兼容性)、`MPEG-DASH`/`Low-Latency DASH` (开放标准)、`WebRTC` (互动)。
  - **点播**：`HLS` 或 `MPEG-DASH` (主流 `ABR`)，`MP4` (简单场景)。
- **播放**：各种平台和设备上的播放器，需要能正确解析所选协议和格式。

理解每种技术的优劣和适用边界，才能做出最明智的决策。 
